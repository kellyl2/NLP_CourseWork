{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<b>Discussion Points</b>\n",
        "<ul>\n",
        "<li>Is one engine better than another? </li>\n",
        "<li>How did the text extractors compare? </li>\n",
        "<li>How did they all compare to the different methods in the Jupyter Notebook? </li>\n",
        "</ul>\n",
        "<p>\n",
        "Think in terms of:\n",
        "<ul>\n",
        "<li>Providing useful terms (however you choose to define them)</li>\n",
        "<li>Catching all the terms that you think it should (precision vs recall)</li>\n",
        "</ul>\n",
        "<p>\n",
        "In addition, note how  the engines perform on:\n",
        "<ul>\n",
        "<li><b>Stemming</b>: coalescing plurals and possessives into a single word, such as \"emails\" => \"email,\" etc.</li>\n",
        "<li><b>Synonyms / Alias:</b> Extracting the same entity, regardless of how the entity is named (\"Bernie Sanders\" vs. \"Bernie\" vs. \"Sanders\") </li>\n",
        "<li>How did the methods in your notebook perform when you included the preprocessing step?</li>\n",
        "</ul>\n",
        "</p>\n",
        "<p>\n",
        "Also, note how the online term extraction engines \"count\" their terms.\n",
        "<ul>\n",
        "<li>TerMine provides two indices; Term Strength and one other. </li>\n",
        "<li>FiveFilters gives you the actual term count. </li>\n",
        "<li>Other term extraction engines provide different outputs. (For example, you could check out the Python NLTK, or Natural Language ToolKit, capability.) </li>\n",
        "<li>You can run the Freq_Dist block in your Notebook to get NLTK based counts.\n",
        "Some of the phrase extractors offer counts too.</li>\n",
        "</ul>\n",
        "</p>\n",
        "<p>\n",
        "Consider and comment.</p>"
      ],
      "metadata": {
        "id": "YKQaKfrhoLa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " <b>Objective:</b> Build a ground-truth term/entity list from your own 10-document movie set, then compare it against online term/entity extractors and programmatic methods (Jupyter/NLTK + other extractors). <br>Reflect on how preprocessing choices affect results, and discuss which methods worked best and why."
      ],
      "metadata": {
        "id": "-xB9IxHoSK24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install dandelion-eu\n",
        "!pip install tenacity\n",
        "!pip install ipynb\n",
        "!pip3 install rake_nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOv8rdZqpROB",
        "outputId": "a421d532-e7ad-44c6-b852-43a4b4de4f39",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: dandelion-eu in /usr/local/lib/python3.12/dist-packages (0.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from dandelion-eu) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from dandelion-eu) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->dandelion-eu) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->dandelion-eu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->dandelion-eu) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->dandelion-eu) (2025.8.3)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (8.5.0)\n",
            "Requirement already satisfied: ipynb in /usr/local/lib/python3.12/dist-packages (0.5.1)\n",
            "Requirement already satisfied: rake_nltk in /usr/local/lib/python3.12/dist-packages (1.0.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from rake_nltk) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFOblH_amolc",
        "outputId": "f179536f-8143-4b7f-cebf-5a6154ded34c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams, FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from rake_nltk import Rake\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive, userdata\n",
        "import json\n",
        "from collections import Counter\n",
        "from openai import OpenAI\n",
        "from tenacity import retry, wait_exponential_jitter, stop_after_attempt\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Dict, Any\n",
        "from dandelion import DataTXT\n",
        "import ipynb\n",
        "import requests\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "## required as I was getting an error when attempting to flatten the reviews to ascii\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## indicator variable that will pull from APIs if True\n",
        "## will import from saved json files if False\n",
        "dev = False"
      ],
      "metadata": {
        "id": "S3kir8KLLfBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load working area\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# environment references\n",
        "destination_folder= userdata.get('destination_folder')\n",
        "data_folder= userdata.get('data_folder')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUXa36n8qVbU",
        "outputId": "ba82b976-7a1a-4f66-818c-0221d2d6bf6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cleaned_text(text):\n",
        "  \"\"\"simple data cleaning - remove the special characters and convert to lower case\"\"\"\n",
        "  cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "  cleaned_text = cleaned_text.lower()\n",
        "  cleaned_text = cleaned_text.rstrip()\n",
        "  return cleaned_text"
      ],
      "metadata": {
        "id": "dKrnadzo2MzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matched_term_list(list_a, list_b):\n",
        "  matched_terms =[]\n",
        "  for i in list_a:\n",
        "    for j in list_b:\n",
        "      if i==j:\n",
        "        if i not in matched_terms:\n",
        "          matched_terms.append(i)\n",
        "      if i in j:\n",
        "        if i not in matched_terms:\n",
        "          matched_terms.append(i)\n",
        "      if j in i:\n",
        "        if i not in matched_terms:\n",
        "          matched_terms.append(i)\n",
        "  return matched_terms"
      ],
      "metadata": {
        "id": "dbQHO9VGsQTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_terms_in_df(df, term_list, alias_terms = {}):\n",
        "  results = {}\n",
        "  for f in df['FileName']:\n",
        "    docfile = f\n",
        "    reference = f[4:9].replace(\"_\", \"\")\n",
        "    results[reference] = {}\n",
        "    for t in term_list:\n",
        "      text = df['MovieReview_normalized'].loc[df['FileName']==f].to_list()[0]\n",
        "      if t in text:\n",
        "        results[reference][t] = text.count(t)\n",
        "      else:\n",
        "        results[reference][t] = 0\n",
        "\n",
        "\n",
        "  df_results = pd.DataFrame.from_dict(results)\n",
        "  df_results['TotalTerms'] = df_results.sum(axis=1, numeric_only=True)\n",
        "\n",
        "  df_results.sort_values(by='TotalTerms', ascending = False, inplace=True)\n",
        "  df_results = df_results.reset_index()\n",
        "  df_results.rename(columns={'index':'Term'}, inplace=True)\n",
        "  df_results = df_results.fillna(0)\n",
        "  if alias_terms != {}:\n",
        "    df_results['alias_terms'] = df_results['Term'].apply(lambda x: alias_terms[x] if x in alias_terms else '')\n",
        "  df_output = df_results.loc[df_results['TotalTerms']>=1]\n",
        "  return df_output"
      ],
      "metadata": {
        "id": "a2hXRORyVppm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Step 1: Manual Term Extraction</b>\n",
        "Using EACH of the documents that you selected previously (your own 10 documents) - manually perform term extraction and entity extraction."
      ],
      "metadata": {
        "id": "ZPrO6nVkmpoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## load manual terms from text file\n",
        "manual_terms_source = os.path.join(destination_folder, \"LCK_TAKEN_MANUAL_Terms.txt\")\n",
        "with open(manual_terms_source, 'r') as file:\n",
        "  delimiter = \",\"\n",
        "  content = file.read()\n",
        "  manual_terms = content.split(delimiter)\n",
        "\n",
        "cleaned_terms = []\n",
        "for m in manual_terms:\n",
        "  cleaned_terms.append(get_cleaned_text(m))\n"
      ],
      "metadata": {
        "id": "8cnMNlQmyqnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load movie reviews into a dataframe\n",
        "movie_reviews = os.path.join(data_folder, \"LCK_MovieReview.csv\")\n",
        "df = pd.read_csv(movie_reviews)\n",
        "\n",
        "#apply a cleansing function (normalize text case, remove special characters)\n",
        "df['MovieReview_normalized'] = df['MovieReview'].apply(get_cleaned_text)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOEihtUO005F",
        "outputId": "3ea877b1-7459-4b18-9dbb-a62af8a0ac3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              FileName                                        MovieReview  \\\n",
            "0   LCK_DOC3_TAKEN.txt  \"Taken,\" which tells the story of how Liam Nee...   \n",
            "1   LCK_DOC9_TAKEN.txt  The conundrum posed by \"Taken\" is as old as ci...   \n",
            "2  LCK_DOC10_TAKEN.txt  The coolest thing in Taken lasts about three s...   \n",
            "3   LCK_DOC7_TAKEN.txt  If CIA agents in general were as skilled as Br...   \n",
            "4   LCK_DOC6_TAKEN.txt  Without ever taking his shirt off, Liam Neeson...   \n",
            "\n",
            "                              MovieReview_normalized  \n",
            "0  taken which tells the story of how liam neeson...  \n",
            "1  the conundrum posed by taken is as old as cine...  \n",
            "2  the coolest thing in taken lasts about three s...  \n",
            "3  if cia agents in general were as skilled as br...  \n",
            "4  without ever taking his shirt off liam neeson ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Manual (Ground Truth) Term count in \"Taken\" movie reviews</h2>"
      ],
      "metadata": {
        "id": "2E1PpEnWOsvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create the combined table that counts the term frequency within the movie reviews\n",
        "df_manual = check_terms_in_df(df, cleaned_terms)\n",
        "df_manual['Ground_Truth'] = df_manual['Term'].apply(lambda x: 1 if x in cleaned_terms else 0)\n",
        "df_manual = df_manual[['Term','Ground_Truth','DOC1','DOC2','DOC3','DOC4','DOC5','DOC6','DOC7','DOC8','DOC9','DOC10','TotalTerms']]\n",
        "## display the top 8 records\n",
        "df_manual.head(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YjjliORr2dkk",
        "outputId": "05592303-05c8-44e9-922f-482b67ce432f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Term  Ground_Truth  DOC1  DOC2  DOC3  DOC4  DOC5  DOC6  DOC7  DOC8  \\\n",
              "0           la             1     8    11    11    10     9    14    14     3   \n",
              "1           us             1    12     9    10     4     7     4    15     7   \n",
              "2          cia             1     4     5     3     0     1     2     6     0   \n",
              "3        paris             1     2     5     1     1     1     4     2     1   \n",
              "4          kim             1     0     3     0     1     0     5     7     0   \n",
              "5  liam neeson             1     1     2     1     1     1     1     3     2   \n",
              "6     albanian             1     0     1     1     1     1     3     1     1   \n",
              "7   luc besson             1     1     1     1     1     0     1     1     1   \n",
              "\n",
              "   DOC9  DOC10  TotalTerms  \n",
              "0    12     15         107  \n",
              "1     6     25          99  \n",
              "2     1      3          25  \n",
              "3     3      5          25  \n",
              "4     3      5          24  \n",
              "5     1      1          14  \n",
              "6     1      1          11  \n",
              "7     1      2          10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39679510-df83-4e53-b6f9-530e4d76b58c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>Ground_Truth</th>\n",
              "      <th>DOC1</th>\n",
              "      <th>DOC2</th>\n",
              "      <th>DOC3</th>\n",
              "      <th>DOC4</th>\n",
              "      <th>DOC5</th>\n",
              "      <th>DOC6</th>\n",
              "      <th>DOC7</th>\n",
              "      <th>DOC8</th>\n",
              "      <th>DOC9</th>\n",
              "      <th>DOC10</th>\n",
              "      <th>TotalTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>la</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cia</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paris</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kim</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>liam neeson</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>albanian</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>luc besson</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39679510-df83-4e53-b6f9-530e4d76b58c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39679510-df83-4e53-b6f9-530e4d76b58c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39679510-df83-4e53-b6f9-530e4d76b58c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b9c334b5-26da-48e3-b145-45ca6c4641c2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9c334b5-26da-48e3-b145-45ca6c4641c2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b9c334b5-26da-48e3-b145-45ca6c4641c2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_manual",
              "summary": "{\n  \"name\": \"df_manual\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Term\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"osama bin laden\",\n          \"french intelligence op\",\n          \"eastern european\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground_Truth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 25,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 107,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The number of manually extracted terms from movie reviews is {len(cleaned_terms)} distinct terms')"
      ],
      "metadata": {
        "id": "1Gwax8DXOVc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606d7eff-f8eb-416c-88a5-1568276ef0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of manually extracted terms from movie reviews is 102 distinct terms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<blockquote>\n",
        "<b>Observation from the frequency count for manually extracted terms</b> the top responses (\"la\" and \"us\") are acronyms for place names (Los Angeles and United States) are also word parts - which explains the frequency of observed values.\n",
        "</blockquote>\n"
      ],
      "metadata": {
        "id": "nrGczMCkOzgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Step 2: Run Two Different Automated Term Extraction Engines. </b>\n",
        "<ul>\n",
        "<li>Pick two online term extractors (e.g., FiveFilters, Dandelion, wordcount.com) and run each on all 10 documents. For this work - I am using online term extractors that have published Application Programming interface (API).\n",
        "<ul>\n",
        "<li>Option 1 - ChatGPT with specific instructions</li>\n",
        "<li>Option 2 - Dandelion</li>\n",
        "</li>\n",
        "</ul>\n",
        "<li>Extend your table to add their metrics/counts per document (for at least the top ~20 terms from your ground truth; more if you can).</li>\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "NLnChtkp7vPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Automated Extraction Engine 1: Generative Pre-trained Transformer (GPT)</h2>\n"
      ],
      "metadata": {
        "id": "VGi5CUvJSvrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## documented user instructions for the gpt input\n",
        "## code reference:\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a precise term extractor. Return ONLY structured JSON per the schema. \"\n",
        "    \"No explanations.\"\n",
        ")\n",
        "\n",
        "USER_INSTRUCTIONS = \"\"\"\\\n",
        "From the text, extract up to {num_terms} high-value domain terms.\n",
        "\n",
        "For each term include:\n",
        "- term (lemma, ≤3 words)\n",
        "- category (entity|noun_phrase|acronym|process|system|metric|place|noun)\n",
        "- confidence (0–1)\n",
        "- frequency count (integer)\n",
        "\n",
        "Rules:\n",
        "- Be conservitive: if unsure, omit.\n",
        "- Merge obvious variants; keep acronyms with expansions.\n",
        "- Exclude generic terms unless qualified (e.g., 'data pipeline' ok, 'data' not).\n",
        "- Prefer domain-specific multiword noun phrases.\n",
        "Text:\n",
        "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "MODEL_NAME = \"gpt-4o\""
      ],
      "metadata": {
        "id": "6uH8Qg89iFHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@retry(wait=wait_exponential_jitter(initial=1, max=20), stop=stop_after_attempt(6))\n",
        "\n",
        "def call_gpt_extractor(client , chunk_text: str, num_terms: int = 40) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Call the Responses API from GPT model.\n",
        "    Requires an OpenAI API key.\n",
        "    \"\"\"\n",
        "    resp = client.responses.create(\n",
        "        model=MODEL_NAME,\n",
        "        input=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": USER_INSTRUCTIONS.format(num_terms=num_terms, text=chunk_text)}\n",
        "        ],\n",
        "        temperature=0.1,\n",
        "    )\n",
        "    json_string = json.loads(resp.output[0].content[0].text[8:-4])\n",
        "    return json_string\n",
        "\n",
        "def call_dandelion_extractor(api_key, chunk_text: str, num_terms: int = 40):\n",
        "    \"\"\"\n",
        "    Call the Responses API.\n",
        "    \"\"\"\n",
        "    resp = api_key.nex(text = chunk_text, top_entities = num_terms, min_length = 3)\n",
        "    return resp\n",
        "\n",
        "def chunk_text(text: str, max_words=1000, overlap_words=100):\n",
        "    \"\"\"\n",
        "    Split long text into overlapping chunks by words.\n",
        "    \"\"\"\n",
        "    N = len(text.split())\n",
        "    words = text.split()\n",
        "    i = 0\n",
        "    while i < N:\n",
        "        j = min(i + max_words, N)\n",
        "        chunk = \" \".join(words[i:j])\n",
        "        yield chunk\n",
        "        i = j - overlap_words if j < N else j\n",
        "\n",
        "def get_extracted_terms(df, api_key, api_option = 'gpt'):\n",
        "  \"\"\"standardized function to call and output the extracted terms from the movie reviews\"\"\"\n",
        "  MAX_WORDS = 1000      ## words per loop\n",
        "  OVERLAP = 10          ## word overlap between loops (to ensure no potential terms are missed)\n",
        "  TOP_K_PER_CHUNK = 15  ## limit results to the top N requests\n",
        "  all_rows = {}         ## generates the results disctionary\n",
        "  all_terms = []        ## generates the consolidated list of terms extracted\n",
        "  for d in range(10):\n",
        "      for i, chunk in enumerate(chunk_text(df[\"MovieReview_normalized\"][d], max_words=MAX_WORDS, overlap_words=OVERLAP)):\n",
        "        #print loop output to see where we are\n",
        "        print(d, i, df['FileName'][d])\n",
        "        ## gpt options\n",
        "        if api_option == 'gpt':\n",
        "          out = call_gpt_extractor(api_key, chunk, num_terms=TOP_K_PER_CHUNK)\n",
        "        ## dandelion options\n",
        "        elif api_option == 'dandelion':\n",
        "          output = call_dandelion_extractor(api_key, chunk_text = chunk, num_terms = TOP_K_PER_CHUNK)\n",
        "          out = output['annotations']\n",
        "\n",
        "        for t in out:\n",
        "          lbl = t['label'] if 'label' in t else t['term']\n",
        "          extracted_term = get_cleaned_text(lbl)\n",
        "          if extracted_term not in all_terms and len(extracted_term)>=3:\n",
        "            all_terms.append(extracted_term)\n",
        "            if 'label' not in t:\n",
        "              all_rows[extracted_term] = {**t}\n",
        "            else:\n",
        "              all_rows[extracted_term] = {'label':extracted_term, 'confidence':t['confidence']}\n",
        "\n",
        "            ## count the number of instances from the term extraction step\n",
        "            all_rows[extracted_term]['identified_count'] = 1\n",
        "\n",
        "          if extracted_term in all_terms:\n",
        "            all_rows[extracted_term]['identified_count'] += 1\n",
        "\n",
        "  print(\"---------COMPLETE -----------\")\n",
        "  return (all_terms, all_rows)"
      ],
      "metadata": {
        "id": "00tZWYcViJGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## generate the terms from GPT api call\n",
        "movie_gpt_terms = os.path.join(destination_folder, \"LCK_GPT_Extracted_Terms.json\")\n",
        "if dev == False:\n",
        "  with open(movie_gpt_terms, 'r') as f:\n",
        "        all_gpt_rows = json.load(f)\n",
        "\n",
        "elif dev == True:\n",
        "  ## calls the apii key from google secrets\n",
        "  client = OpenAI(api_key=userdata.get('gpt') )\n",
        "  ## calls the data extractor function\n",
        "  all_gpt_terms, all_gpt_rows = get_extracted_terms(df, client, api_option = 'gpt')\n",
        "  ## save results\n",
        "  with open(movie_gpt_terms, 'w') as f:\n",
        "        json.dump(all_gpt_rows, f, indent=4)\n"
      ],
      "metadata": {
        "id": "QZGIGBaMiuDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_gpt_rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-XzZCsIHBeA",
        "outputId": "846f0cf2-b7db-4cad-fc84-b0c190beed92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'liam neeson': {'term': 'Liam Neeson',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 2,\n",
              "  'identified_count': 9},\n",
              " 'bryan mills': {'term': 'Bryan Mills',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 2,\n",
              "  'identified_count': 8},\n",
              " 'cia spook': {'term': 'CIA spook',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'los angeles mansion': {'term': 'Los Angeles mansion',\n",
              "  'category': 'place',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'industrialist husband': {'term': 'industrialist husband',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'obama administration': {'term': 'Obama administration',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'french producer': {'term': 'French producer',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'charles de gaulle international': {'term': 'Charles de Gaulle International',\n",
              "  'category': 'place',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'sex traffickers': {'term': 'sex traffickers',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'oskar schindler': {'term': 'Oskar Schindler',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'eiffel tower': {'term': 'Eiffel Tower',\n",
              "  'category': 'place',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 4},\n",
              " 'jason bourne': {'term': 'Jason Bourne',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'charles bronson simplicity': {'term': 'Charles Bronson simplicity',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'pierre morel': {'term': 'Pierre Morel',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 7},\n",
              " 'district b13': {'term': 'District B13',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 6},\n",
              " 'foreign intrigue': {'term': 'foreign intrigue',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'cia': {'term': 'CIA',\n",
              "  'category': 'acronym',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 3},\n",
              " 'los angeles': {'term': 'Los Angeles',\n",
              "  'category': 'place',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 3},\n",
              " 'sex trafficking': {'term': 'sex trafficking',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.95,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'luc besson': {'term': 'Luc Besson',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 8},\n",
              " 'james bond': {'term': 'James Bond',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 3},\n",
              " 'symbolic paranoia': {'term': 'symbolic paranoia',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'american foreign policy': {'term': 'American foreign policy',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'stunt team': {'term': 'stunt team',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'action movie': {'term': 'action movie',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 2,\n",
              "  'identified_count': 2},\n",
              " 'phone message': {'term': 'phone message',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'particular set of skills': {'term': 'particular set of skills',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'torture porn': {'term': 'torture porn',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'white slave ring': {'term': 'white slave ring',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'consumer protection squad': {'term': 'consumer protection squad',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'parkour': {'term': 'parkour',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 2,\n",
              "  'identified_count': 2},\n",
              " 'cinematographer': {'term': 'cinematographer',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'box office': {'term': 'box office',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'cia superman': {'term': 'cia superman',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'psychological wrinkle': {'term': 'psychological wrinkle',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'charles de gaulle airport': {'term': 'charles de gaulle airport',\n",
              "  'category': 'place',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'albanian nasties': {'term': 'albanian nasties',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'preternatural status': {'term': 'preternatural status',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'french police chief': {'term': 'french police chief',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'action choreography': {'term': 'action choreography',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'plausibility factor': {'term': 'plausibility factor',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'thriller genre': {'term': 'thriller genre',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'cop film': {'term': 'cop film',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'french connection': {'term': 'french connection',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.95,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'oscar for best picture': {'term': 'oscar for best picture',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'cia agent': {'term': 'CIA agent',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 2,\n",
              "  'identified_count': 5},\n",
              " 'osama bin laden': {'term': 'Osama bin Laden',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.95,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'rescue squad': {'term': 'rescue squad',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'sharpshooting': {'term': 'sharpshooting',\n",
              "  'category': 'process',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'langley': {'term': 'Langley',\n",
              "  'category': 'place',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'marko': {'term': 'Marko',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'albanian ring': {'term': 'Albanian ring',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'prostitutes': {'term': 'prostitutes',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'arab sheiks': {'term': 'Arab sheiks',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'spycraft': {'term': 'spycraft',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'armed combat': {'term': 'armed combat',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'french police': {'term': 'French police',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'bourne thriller': {'term': 'Bourne thriller',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'taken': {'term': 'Taken',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency': 1,\n",
              "  'identified_count': 3},\n",
              " 'paris': {'term': 'Paris',\n",
              "  'category': 'place',\n",
              "  'confidence': 1,\n",
              "  'frequency': 2,\n",
              "  'identified_count': 5},\n",
              " 'whiteslave traders': {'term': 'white-slave traders',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency': 1,\n",
              "  'identified_count': 2},\n",
              " 'euro shootemups': {'term': 'Euro shoot-em-ups',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency': 1,\n",
              "  'identified_count': 2},\n",
              " 'eurocorp': {'term': 'Eurocorp',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency': 1,\n",
              "  'identified_count': 2},\n",
              " 'actioner': {'term': 'actioner',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.8,\n",
              "  'frequency': 2,\n",
              "  'identified_count': 2},\n",
              " 'jason bournelike skills': {'term': 'Jason Bourne-like skills',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency': 1,\n",
              "  'identified_count': 2},\n",
              " 'private jets': {'term': 'private jets',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency': 1,\n",
              "  'identified_count': 2},\n",
              " 'french intelligence': {'term': 'French intelligence',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency': 1,\n",
              "  'identified_count': 2},\n",
              " 'black ops action hero': {'term': 'black ops action hero',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'irish actor': {'term': 'Irish actor',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 3},\n",
              " 'jedi master quigon jinn': {'term': 'Jedi Master Qui-Gon Jinn',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'steven spielberg': {'term': 'Steven Spielberg',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'revenge thriller': {'term': 'revenge thriller',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'maggie grace': {'term': 'Maggie Grace',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'famke janssen': {'term': 'Famke Janssen',\n",
              "  'category': 'entity',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 4},\n",
              " 'slaveryprostitution ring': {'term': 'slavery-prostitution ring',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'albanian thugs': {'term': 'Albanian thugs',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'bournelike manhunt': {'term': 'Bourne-like manhunt',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'action thriller': {'term': 'action thriller',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.95,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 4},\n",
              " 'retired spy': {'term': 'retired spy',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.92,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'albanian sex traffickers': {'term': 'Albanian sex traffickers',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.97,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'indianapolis international film festival': {'term': 'Indianapolis International Film Festival',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.97,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'action film': {'term': 'action film',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.95,\n",
              "  'frequency_count': 3,\n",
              "  'identified_count': 2},\n",
              " 'indiana jones': {'term': 'Indiana Jones',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.98,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'michael caine': {'term': 'Michael Caine',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.98,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'renee zellweger': {'term': 'Renee Zellweger',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.98,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'super bowl sunday': {'term': 'Super Bowl Sunday',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.97,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'director': {'term': 'director',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'robert mark kamen': {'term': 'Robert Mark Kamen',\n",
              "  'category': 'entity',\n",
              "  'confidence': 0.95,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'international cabal': {'term': 'international cabal',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'abduction scene': {'term': 'abduction scene',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'expert craftsmanship': {'term': 'expert craftsmanship',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.85,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'avenging action hero': {'term': 'avenging action hero',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'thriller': {'term': 'thriller',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'international undercover agent': {'term': 'international undercover agent',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'beirut': {'term': 'Beirut',\n",
              "  'category': 'place',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'road map of cliches': {'term': 'road map of cliches',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'improbable escapes': {'term': 'improbable escapes',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'trafficking in women': {'term': 'trafficking in women',\n",
              "  'category': 'process',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'crime boss': {'term': 'crime boss',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'construction site': {'term': 'construction site',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'driverside window': {'term': 'driverside window',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.8,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'preventer': {'term': 'preventer',\n",
              "  'category': 'noun',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'california': {'term': 'California',\n",
              "  'category': 'place',\n",
              "  'confidence': 1,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'albanian white slavers': {'term': 'Albanian white slavers',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.95,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'electric chair': {'term': 'electric chair',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2},\n",
              " 'arab sheik': {'term': 'Arab sheik',\n",
              "  'category': 'noun_phrase',\n",
              "  'confidence': 0.9,\n",
              "  'frequency_count': 1,\n",
              "  'identified_count': 2}}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The total number of unique terms extracted using GPT {MODEL_NAME} for the {df.shape[0]} movie reviews is {len(all_gpt_rows.keys())}')\n",
        "print(list(all_gpt_rows.keys())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuGW3Al3La6p",
        "outputId": "33c83c9a-0954-467e-fa02-b185b8010491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of unique terms extracted using GPT gpt-4o for the 10 movie reviews is 106\n",
            "['liam neeson', 'bryan mills', 'cia spook', 'los angeles mansion', 'industrialist husband', 'obama administration', 'french producer', 'charles de gaulle international', 'sex traffickers', 'oskar schindler']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_manual_matched_terms = get_matched_term_list(list(all_gpt_rows.keys()), cleaned_terms)\n",
        "\n",
        "print(f'The number of matched terms between the manual method and GPT {MODEL_NAME} for the {df.shape[0]} movie reviews is {len(gpt_manual_matched_terms)}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv1wCSDXRjgK",
        "outputId": "6f16c338-c08f-4c2f-8242-4b95ba570441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of matched terms between the manual method and GPT gpt-4o for the 10 movie reviews is 57.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automated Extraction Engine 2: Dandelion"
      ],
      "metadata": {
        "id": "3xEnBq0JjLS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dandelion_terms = os.path.join(destination_folder, \"LCK_Dandelion_Extracted_Terms.json\")\n",
        "if dev == False:\n",
        "  with open(movie_dandelion_terms, 'r') as f:\n",
        "        all_dandelion_rows = json.load(f)\n",
        "elif dev == True:\n",
        "  term_extractor_dandelion = \"https://dandelion.eu/\"\n",
        "  datatxt = DataTXT(token = userdata.get('dandelion_api'))\n",
        "  all_dandelion_terms, all_dandelion_rows = get_extracted_terms(df, datatxt, api_option = 'dandelion')\n",
        "  ## save results\n",
        "  with open(movie_dandelion_terms, 'w') as f:\n",
        "        json.dump(all_dandelion_rows, f, indent=4)"
      ],
      "metadata": {
        "id": "AIqP39tmjKUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The total number of unique terms extracted using dandelion_api for the {df.shape[0]} movie reviews is {len(all_dandelion_rows.keys())}')\n",
        "print(list(all_dandelion_rows.keys())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8_iu1GDrMP2",
        "outputId": "3073f391-065f-45b9-def8-ea3ffc43ed3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of unique terms extracted using dandelion_api for the 10 movie reviews is 273\n",
            "['liam neeson', 'gasket', 'france', 'albanian', 'labrador retriever', 'cia', 'black pudding', 'family', 'los angeles', 'industrialist']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dandelion_manual_matched_terms = get_matched_term_list(list(all_dandelion_rows.keys()), cleaned_terms)\n",
        "print(f'The number of matched terms between the manual method and dandelion_api for the {df.shape[0]} movie reviews is {len(dandelion_manual_matched_terms)}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBLIK4coSNcl",
        "outputId": "890e6ce3-580d-4c4c-f7df-42bb869409d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of matched terms between the manual method and dandelion_api for the 10 movie reviews is 87.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<blockquote>\n",
        "<b>Initial Observations of term automated extractors (GPT & Dandelion)</b> for 10 movie reviews of the movie Taken:<br>\n",
        "<ul>\n",
        "<li>The total number of <b>danelion</b> extracted terms is 273</li>\n",
        "<li>The total number of <b>GPT gpt-4o</b> extracted terms is 111</li>\n",
        "</ul>\n",
        "<p>\n",
        "One of the key differentiators between the results from GPT and danelion api was the instruction to the GPT api.\n",
        "</p>\n",
        "<p><i>\n",
        "Rules for the GPT prompt response:\n",
        "<ul>\n",
        "<li>Be conservitive; if unsure, omit.</li>\n",
        "<li>Merge obvious variants; keep acronyms with expansions.</li>\n",
        "</i></ul>\n",
        "</p>\n",
        "\n",
        "</blockquote>"
      ],
      "metadata": {
        "id": "H2xP-g5yrh2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matched_terms_automated = get_matched_term_list(list(all_gpt_rows.keys()), list(all_dandelion_rows.keys()))\n",
        "print(f'The number of matched terms between the two methods is {len(matched_terms_automated)}.')\n",
        "print(f'A sample of the  matched terms between the two sources are: {matched_terms_automated[:10]}')"
      ],
      "metadata": {
        "id": "dvVcqKTVPOhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68aa624-9985-479f-de8e-a62a566147b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of matched terms between the two methods is 73.\n",
            "A sample of the  matched terms between the two sources are: ['liam neeson', 'cia spook', 'los angeles mansion', 'industrialist husband', 'french producer', 'charles de gaulle international', 'oskar schindler', 'eiffel tower', 'jason bourne', 'charles bronson simplicity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_term_list = list(all_gpt_rows.keys()) + list(all_dandelion_rows.keys())+ cleaned_terms\n",
        "## remove duplicates\n",
        "merged_term_list = list(set(merged_term_list))\n",
        "print(f'The number of terms between the two automated and manual methods: {len(merged_term_list)}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6cJgkUWUb0D",
        "outputId": "cec31063-d8fb-4697-c62a-c1ab44667b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of terms between the two automated and manual methods: 390.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_automated_gpt_check = check_terms_in_df(df, merged_term_list)\n",
        "df_automated_gpt_check['Ground_Truth'] = df_automated_gpt_check['Term'].apply(lambda x: 1 if x in cleaned_terms else 0)\n",
        "df_automated_gpt_check['GPT'] = df_automated_gpt_check['Term'].apply(lambda x: 1 if x in list(all_gpt_rows.keys()) else 0)\n",
        "df_automated_gpt_check['Dandelion'] = df_automated_gpt_check['Term'].apply(lambda x: 1 if x in list(all_dandelion_rows.keys()) else 0)\n",
        "df_automated_gpt_check = df_automated_gpt_check[['Term','Ground_Truth','GPT','Dandelion','DOC1','DOC2','DOC3','DOC4','DOC5','DOC6','DOC7','DOC8','DOC9','DOC10','TotalTerms']]\n",
        "df_automated_gpt_check.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "qhyLq_GeRUTd",
        "outputId": "9edfb17b-615c-4f7a-d635-4117616dfedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Term  Ground_Truth  GPT  Dandelion  DOC1  DOC2  DOC3  DOC4  DOC5  \\\n",
              "0            la             1    0          0     8    11    11    10     9   \n",
              "1            us             1    0          0    12     9    10     4     7   \n",
              "2         taken             0    1          1    11     3     2     1     4   \n",
              "3           ive             0    0          1     3     5     3     3     3   \n",
              "4        action             0    0          1     4     2     1     2     3   \n",
              "5          film             0    0          1     3     1     1     0     3   \n",
              "6           cia             1    1          1     4     5     3     0     1   \n",
              "7         paris             1    1          1     2     5     1     1     1   \n",
              "8           kim             1    0          0     0     3     0     1     0   \n",
              "9         other             0    0          1     1     0     0     3     0   \n",
              "10  liam neeson             1    1          1     1     2     1     1     1   \n",
              "11       french             0    0          1     0     1     2     1     0   \n",
              "12      albania             0    0          1     0     1     1     1     1   \n",
              "13     albanian             1    0          1     0     1     1     1     1   \n",
              "14         euro             0    0          1     0     1     3     0     0   \n",
              "\n",
              "    DOC6  DOC7  DOC8  DOC9  DOC10  TotalTerms  \n",
              "0     14    14     3    12     15         107  \n",
              "1      4    15     7     6     25          99  \n",
              "2      1     3    15     3      6          49  \n",
              "3      3     6     5     5      6          42  \n",
              "4      4     4    12     0      5          37  \n",
              "5      0     1     6     1      9          25  \n",
              "6      2     6     0     1      3          25  \n",
              "7      4     2     1     3      5          25  \n",
              "8      5     7     0     3      5          24  \n",
              "9      2     3     1     2      5          17  \n",
              "10     1     3     2     1      1          14  \n",
              "11     1     1     0     1      6          13  \n",
              "12     3     1     1     1      1          11  \n",
              "13     3     1     1     1      1          11  \n",
              "14     3     0     0     2      1          10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e088d8a4-8976-41ab-9942-56e89f711040\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>Ground_Truth</th>\n",
              "      <th>GPT</th>\n",
              "      <th>Dandelion</th>\n",
              "      <th>DOC1</th>\n",
              "      <th>DOC2</th>\n",
              "      <th>DOC3</th>\n",
              "      <th>DOC4</th>\n",
              "      <th>DOC5</th>\n",
              "      <th>DOC6</th>\n",
              "      <th>DOC7</th>\n",
              "      <th>DOC8</th>\n",
              "      <th>DOC9</th>\n",
              "      <th>DOC10</th>\n",
              "      <th>TotalTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>la</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>taken</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>action</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>film</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cia</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>paris</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>kim</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>liam neeson</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>french</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>albania</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>albanian</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>euro</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e088d8a4-8976-41ab-9942-56e89f711040')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e088d8a4-8976-41ab-9942-56e89f711040 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e088d8a4-8976-41ab-9942-56e89f711040');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-068a6fc0-7e7e-40ee-be00-e065626110f6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-068a6fc0-7e7e-40ee-be00-e065626110f6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-068a6fc0-7e7e-40ee-be00-e065626110f6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_automated_gpt_check",
              "summary": "{\n  \"name\": \"df_automated_gpt_check\",\n  \"rows\": 299,\n  \"fields\": [\n    {\n      \"column\": \"Term\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 299,\n        \"samples\": [\n          \"body count\",\n          \"afghanistan\",\n          \"driverside window\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground_Truth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dandelion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          11,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          11,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          9,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          14,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          7,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          12,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 25,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4,\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1,\n        \"max\": 107,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          107,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Step 3: Programmatic extraction (Notebook)</b></h2>\n",
        "<ul>\n",
        "<li>Run the provided term_extraction_exploration.ipynb (NLTK tokenizer + optional phrase extractors).</li>\n",
        "<li>Apply the extracted term results to each of the 10 documents</li>\n",
        "<li>Record comparable counts/metrics and compare to your ground truth and online tools</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "IjMBVlfyWKgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Programmatic extraction: NLTK Tokenizer</h2>\n",
        "\n",
        "Using the nltk tokenizer methods, return phrases that have been extracted from the reviews"
      ],
      "metadata": {
        "id": "PcYwCoajQHGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## code reference from discussion 2 term extraction code sample\n",
        "## reference: Jennifer Sleeman\n",
        "\n",
        "#Get Frequ Dist\n",
        "def get_freq_dist(terms):\n",
        "    all_counts = dict()\n",
        "    all_counts = FreqDist(terms)\n",
        "    return all_counts\n",
        "\n",
        "# Rake Keyword Extractor\n",
        "def run_rake(in_text):\n",
        "    r = Rake(max_length=3, include_repeated_phrases = False)\n",
        "    r.extract_keywords_from_text(in_text)\n",
        "    rake_phrases= r.get_ranked_phrases()\n",
        "    scores = r.get_ranked_phrases_with_scores()\n",
        "    return scores"
      ],
      "metadata": {
        "id": "l3UqXVySGEb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format the text in the dataframe.\n",
        "<ol>\n",
        "<li>Split sentances to generate a list of sentances.</li>\n",
        "<li>Apply the text cleaning function (lowercase, remove punctuation)</li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "iFoXm9PTQtjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## format dataframe for nltk functions\n",
        "df['Review_Sentences'] = df['MovieReview'].str.split(r'.', expand=False)\n",
        "df['Review_Sentences'] = df['Review_Sentences'].apply(lambda x: [get_cleaned_text(item) for item in x])"
      ],
      "metadata": {
        "id": "IfVOVhdt5J91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## from discussion 2 term extraction code sample\n",
        "## reference: Jennifer Sleeman\n",
        "extracted_terms = []\n",
        "for i in range(10):\n",
        "  sentences = df['Review_Sentences'][i]\n",
        "  all_terms=[]\n",
        "  for sentence in sentences:\n",
        "    all_terms = all_terms + run_rake(sentence)\n",
        "  #get the frequency distribution across the terms\n",
        "  fd=get_freq_dist(all_terms).most_common(15)\n",
        "\n",
        "  for t in fd:\n",
        "    if t[0][1] not in extracted_terms:\n",
        "      extracted_terms.append(t[0][1])"
      ],
      "metadata": {
        "id": "PtYM6ChlF3-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'For nltk term extraction from the 10 movie reviews there were {len(extracted_terms)} terms occured most frequently in the review sentences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4pbMeJAOasK",
        "outputId": "a2e9d060-c880-469a-b1dd-44e47e00db54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For nltk term extraction from the 10 movie reviews there were 131 terms occured most frequently in the review sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_terms_nltk = get_matched_term_list(extracted_terms, merged_term_list)\n",
        "matched_terms_manual = get_matched_term_list(cleaned_terms, extracted_terms)\n",
        "print(f'The number of matched terms between the previous methods and nltk methods: {len(matched_terms_nltk)}.')\n",
        "print(f'The number of matched terms between the manual methods and nltk methods: {len(matched_terms_manual)}.')\n",
        "print(f'A sample of the matched terms between the methods are: {matched_terms_nltk[:6]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daD39DmqXM_2",
        "outputId": "0ed6525f-064b-4b93-adcd-ec2997d89958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of matched terms between the previous methods and nltk methods: 63.\n",
            "The number of matched terms between the manual methods and nltk methods: 27.\n",
            "A sample of the matched terms between the methods are: ['neeson', 'taken', 'liam neeson blows', 'kills 75 albanians', 'deeply insane', 'gasket']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_term_list = merged_term_list + extracted_terms\n",
        "## remove duplicates\n",
        "merged_term_list = list(set(merged_term_list))\n",
        "\n",
        "## generate dataframe frequncy count in reviews\n",
        "df_nltk_check = check_terms_in_df(df, merged_term_list)\n",
        "df_nltk_check['Ground_Truth'] = df_nltk_check['Term'].apply(lambda x: 1 if x in cleaned_terms else 0)\n",
        "df_nltk_check['GPT'] = df_nltk_check['Term'].apply(lambda x: 1 if x in list(all_gpt_rows.keys()) else 0)\n",
        "df_nltk_check['Dandelion'] = df_nltk_check['Term'].apply(lambda x: 1 if x in list(all_dandelion_rows.keys()) else 0)\n",
        "df_nltk_check['NLTK'] = df_nltk_check['Term'].apply(lambda x: 1 if x in extracted_terms else 0)\n",
        "df_nltk_check = df_nltk_check[['Term','Ground_Truth','GPT','Dandelion','NLTK','DOC1','DOC2','DOC3','DOC4','DOC5','DOC6','DOC7','DOC8','DOC9','DOC10','TotalTerms']]\n",
        "df_nltk_check.head(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "lnPORSgcO-Uc",
        "outputId": "043a90fa-5996-4cbd-954d-13719d079690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Term  Ground_Truth  GPT  Dandelion  NLTK  DOC1  DOC2  DOC3  DOC4  \\\n",
              "0         la             1    0          0     0     8    11    11    10   \n",
              "1         us             1    0          0     0    12     9    10     4   \n",
              "2        one             0    0          0     1     8     8     2     7   \n",
              "3      taken             0    1          1     1    11     3     2     1   \n",
              "4        end             0    0          0     1     4     6     5     2   \n",
              "5        ive             0    0          1     0     3     5     3     3   \n",
              "6      bryan             0    0          0     1     0     7     7     4   \n",
              "7        man             0    0          0     1     5     4     1     1   \n",
              "8     action             0    0          1     1     4     2     1     2   \n",
              "9     neeson             0    0          0     1     2     2     5     5   \n",
              "10     movie             0    0          0     1     6     1     1     3   \n",
              "11  daughter             0    0          0     1     2     3     7     5   \n",
              "\n",
              "    DOC5  DOC6  DOC7  DOC8  DOC9  DOC10  TotalTerms  \n",
              "0      9    14    14     3    12     15         107  \n",
              "1      7     4    15     7     6     25          99  \n",
              "2      2     8    15     3     6      9          68  \n",
              "3      4     1     3    15     3      6          49  \n",
              "4      2     2     3     2     5     12          43  \n",
              "5      3     3     6     5     5      6          42  \n",
              "6      1     6     1     3     1     10          40  \n",
              "7      1     3     2     3     3     15          38  \n",
              "8      3     4     4    12     0      5          37  \n",
              "9      4     3     3     5     5      3          37  \n",
              "10     1     2     5     0     2     15          36  \n",
              "11     3     2     3     1     2      6          34  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1841e561-9cf8-42a6-8fac-64f988feb9a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>Ground_Truth</th>\n",
              "      <th>GPT</th>\n",
              "      <th>Dandelion</th>\n",
              "      <th>NLTK</th>\n",
              "      <th>DOC1</th>\n",
              "      <th>DOC2</th>\n",
              "      <th>DOC3</th>\n",
              "      <th>DOC4</th>\n",
              "      <th>DOC5</th>\n",
              "      <th>DOC6</th>\n",
              "      <th>DOC7</th>\n",
              "      <th>DOC8</th>\n",
              "      <th>DOC9</th>\n",
              "      <th>DOC10</th>\n",
              "      <th>TotalTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>la</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>one</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>taken</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>end</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bryan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>man</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>action</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>neeson</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>movie</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>daughter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1841e561-9cf8-42a6-8fac-64f988feb9a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1841e561-9cf8-42a6-8fac-64f988feb9a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1841e561-9cf8-42a6-8fac-64f988feb9a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-550cecc3-9bad-423e-bf25-8f3f0c22066c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-550cecc3-9bad-423e-bf25-8f3f0c22066c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-550cecc3-9bad-423e-bf25-8f3f0c22066c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_nltk_check",
              "summary": "{\n  \"name\": \"df_nltk_check\",\n  \"rows\": 414,\n  \"fields\": [\n    {\n      \"column\": \"Term\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 414,\n        \"samples\": [\n          \"stunt team\",\n          \"jason bournelike skills\",\n          \"industrialist husband\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground_Truth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dandelion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NLTK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          5,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          2,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 25,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 107,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          3,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Programmatic extraction: Google API</h2>\n",
        "\n",
        "Using the Google NLP Term Extractor API, return phrases that have been extracted from the reviews"
      ],
      "metadata": {
        "id": "_Ge1g1ALcHg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## using Google NLP for entity extraction\n",
        "API_KEY = data_folder= userdata.get('google_api')\n",
        "\n",
        "def get_google_nlp_entities(extract_text, api_key):\n",
        "  API_ENDPOINT = f\"https://language.googleapis.com/v1/documents:analyzeEntities?key={API_KEY}\"\n",
        "  # Request content\n",
        "  request_body = {\"document\": {\"content\": extract_text, \"type\": \"PLAIN_TEXT\"}, \"encodingType\": \"UTF8\" }\n",
        "  try:\n",
        "    output = {}\n",
        "    response = requests.post(API_ENDPOINT, json=request_body)\n",
        "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "    ## loop through the response items to capture the top results\n",
        "    for e in response.json()['entities']:\n",
        "      if e['salience'] >=0.01:\n",
        "        if e['name'] not in output:\n",
        "          output[e['name']] ={'type':e['type'],\n",
        "                              'salience': round(e['salience'],3),\n",
        "                              'count': len(e['mentions'][0].keys())}\n",
        "        else:\n",
        "          output[e['name']]['count'] += len(e['mentions'][0].keys())\n",
        "    return output\n",
        "  except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error making API request: {e}\")\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            print(f\"Response content: {e.response.text}\")\n",
        "##NOTES\n",
        "##Salience score [0.0, 1.0]\n",
        "#Scores closer to 0.0: suggest the entity is less important or central to the document.\n",
        "#Scores closer to 1.0: indicate the entity is highly important or central to the document.\n",
        "#Score can be valuable for Information retrieval, Summarization, Content analysis\n",
        "## reference: https://www.601media.com/google-salience-score-what-is-it/"
      ],
      "metadata": {
        "id": "sehS-9bcWnIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_google_extract_terms = os.path.join(destination_folder, \"LCK_google_nlp_Extracted_Terms.json\")\n",
        "if dev == False:\n",
        "  with open(movie_google_extract_terms, 'r') as f:\n",
        "        google_extract_terms = json.load(f)\n",
        "elif dev == True:\n",
        "  google_extract_terms = {}\n",
        "  for r in df['FileName'].unique():\n",
        "    review_text = df['MovieReview_normalized'].loc[df['FileName']==r].to_list()[0]\n",
        "    google_extract_terms[r] = get_google_nlp_entities(review_text, API_KEY)\n",
        "  ## save results\n",
        "  with open(movie_google_extract_terms, 'w') as f:\n",
        "        json.dump(google_extract_terms, f, indent=4)"
      ],
      "metadata": {
        "id": "w9TJV11ZnYn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_results = []\n",
        "for r in google_extract_terms:\n",
        "  for t in list(google_extract_terms[r].keys()):\n",
        "    if t not in google_results:\n",
        "      google_results.append(t)\n",
        "print(f'Google NPL Term Extraction API for the 10 movie reviews there were {len(google_results)} terms occured most frequently in the review sentences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NqqdaiRcqBg",
        "outputId": "4428c726-3dea-451c-ab72-079ce2d200f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google NPL Term Extraction API for the 10 movie reviews there were 152 terms occured most frequently in the review sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_terms_google = get_matched_term_list(google_results, merged_term_list)\n",
        "matched_terms_manual = get_matched_term_list(cleaned_terms, google_results)\n",
        "print(f'The number of matched terms between the previous methods and Google NLP Term Extraction: {len(matched_terms_google)}.')\n",
        "print(f'The number of matched terms between the manual methods and Google NLP Term Extraction: {len(matched_terms_manual)}.')\n",
        "print(f'A sample of the matched terms between the methods are: {matched_terms_google[:6]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5DZ5aCKeENw",
        "outputId": "24cb8714-67e5-4e8a-878d-0e5a9dca3ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of matched terms between the previous methods and Google NLP Term Extraction: 118.\n",
            "The number of matched terms between the manual methods and Google NLP Term Extraction: 37.\n",
            "A sample of the matched terms between the methods are: ['neeson', 'daughter', 'thing', 'spook', 'story', 'eagerness']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_term_list = merged_term_list + google_results\n",
        "## remove duplicates\n",
        "merged_term_list = list(set(merged_term_list))\n",
        "\n",
        "## generate dataframe frequncy count in reviews\n",
        "df_google_check = check_terms_in_df(df, merged_term_list)\n",
        "df_google_check['Ground_Truth'] = df_google_check['Term'].apply(lambda x: 1 if x in cleaned_terms else 0)\n",
        "df_google_check['GPT'] = df_google_check['Term'].apply(lambda x: 1 if x in list(all_gpt_rows.keys()) else 0)\n",
        "df_google_check['Dandelion'] = df_google_check['Term'].apply(lambda x: 1 if x in list(all_dandelion_rows.keys()) else 0)\n",
        "df_google_check['NLTK'] = df_google_check['Term'].apply(lambda x: 1 if x in extracted_terms else 0)\n",
        "df_google_check['Google'] = df_google_check['Term'].apply(lambda x: 1 if x in google_results else 0)\n",
        "df_google_check = df_google_check[['Term','Ground_Truth','GPT','Dandelion','NLTK','Google','DOC1','DOC2','DOC3','DOC4','DOC5','DOC6','DOC7','DOC8','DOC9','DOC10','TotalTerms']]\n",
        "df_google_check.head(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "6NHSytxfeyTf",
        "outputId": "c14678a4-ab64-476c-8b72-6b2669951fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Term  Ground_Truth  GPT  Dandelion  NLTK  Google  DOC1  DOC2  DOC3  \\\n",
              "0       la             1    0          0     0       0     8    11    11   \n",
              "1       us             1    0          0     0       0    12     9    10   \n",
              "2       no             0    0          0     0       1     8    11     8   \n",
              "3      one             0    0          0     1       1     8     8     2   \n",
              "4    taken             0    1          1     1       0    11     3     2   \n",
              "5      all             0    0          0     0       1     6     6     4   \n",
              "6      end             0    0          0     1       0     4     6     5   \n",
              "7      ive             0    0          1     0       0     3     5     3   \n",
              "8    bryan             0    0          0     1       1     0     7     7   \n",
              "9      man             0    0          0     1       1     5     4     1   \n",
              "10  neeson             0    0          0     1       1     2     2     5   \n",
              "11  action             0    0          1     1       1     4     2     1   \n",
              "\n",
              "    DOC4  DOC5  DOC6  DOC7  DOC8  DOC9  DOC10  TotalTerms  \n",
              "0     10     9    14    14     3    12     15         107  \n",
              "1      4     7     4    15     7     6     25          99  \n",
              "2      2     7     7     8    11    10     21          93  \n",
              "3      7     2     8    15     3     6      9          68  \n",
              "4      1     4     1     3    15     3      6          49  \n",
              "5      2     2     3     4     6     3      8          44  \n",
              "6      2     2     2     3     2     5     12          43  \n",
              "7      3     3     3     6     5     5      6          42  \n",
              "8      4     1     6     1     3     1     10          40  \n",
              "9      1     1     3     2     3     3     15          38  \n",
              "10     5     4     3     3     5     5      3          37  \n",
              "11     2     3     4     4    12     0      5          37  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40769e3f-6860-4294-9bed-a699aeca4b44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>Ground_Truth</th>\n",
              "      <th>GPT</th>\n",
              "      <th>Dandelion</th>\n",
              "      <th>NLTK</th>\n",
              "      <th>Google</th>\n",
              "      <th>DOC1</th>\n",
              "      <th>DOC2</th>\n",
              "      <th>DOC3</th>\n",
              "      <th>DOC4</th>\n",
              "      <th>DOC5</th>\n",
              "      <th>DOC6</th>\n",
              "      <th>DOC7</th>\n",
              "      <th>DOC8</th>\n",
              "      <th>DOC9</th>\n",
              "      <th>DOC10</th>\n",
              "      <th>TotalTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>la</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>one</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>taken</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>all</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>end</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>bryan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>man</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>neeson</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>action</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40769e3f-6860-4294-9bed-a699aeca4b44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40769e3f-6860-4294-9bed-a699aeca4b44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40769e3f-6860-4294-9bed-a699aeca4b44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-84bfd708-f186-4f10-a54e-01f5278f9f79\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84bfd708-f186-4f10-a54e-01f5278f9f79')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-84bfd708-f186-4f10-a54e-01f5278f9f79 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_google_check",
              "summary": "{\n  \"name\": \"df_google_check\",\n  \"rows\": 511,\n  \"fields\": [\n    {\n      \"column\": \"Term\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 511,\n        \"samples\": [\n          \"torture\",\n          \"point\",\n          \"56 hes taken\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground_Truth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dandelion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NLTK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Google\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          5,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          6,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 25,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          5,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 107,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          1,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Step 4: Prepocessing Exploration</h2>\n",
        "<ul>\n",
        "<li>Experiment with lowercasing, stop-word removal, stemming, and combinations.</li>\n",
        "<li>Note how these choices change extracted terms (better/worse, noise introduced/removed).</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "Kod1w6obRjRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text normalization thus far has focused on converting the strings to lower case and removing special characters."
      ],
      "metadata": {
        "id": "8WeNY17UhMr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of stop words from nltk\n",
        "stop_words = list(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "d0S8yDXSi156"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_with_char = [x for x in stop_words if x.find(\"'\") != -1]\n",
        "for x in list_with_char:\n",
        "  if get_cleaned_text(x) not in stop_words:\n",
        "    stop_words.append(get_cleaned_text(x))\n",
        "stop_words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfvAo5KukSXX",
        "outputId": "cbd25c12-f5c5-4497-bb61-e746427416ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'about', 'above', 'after', 'again']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_special_chars_and_digits(in_text):\n",
        "    # Remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",in_text)\n",
        "    return text\n",
        "# Remove stop words\n",
        "def remove_stop_words(in_text, stop_words):\n",
        "    word_tokens = word_tokenize(in_text)\n",
        "    updated_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    filtered_sentence = \" \".join(updated_sentence)\n",
        "    return filtered_sentence\n"
      ],
      "metadata": {
        "id": "Qz8UHcn0qZdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['preprocessed_text_count'] = df['Review_Sentences'].apply(lambda x: sum(map(len, x)))\n",
        "## process text in sentences\n",
        "df['processed_sentence'] = df['Review_Sentences'].apply(lambda x: [remove_special_chars_and_digits(item) for item in x])\n",
        "df['processed_sentence'] = df['processed_sentence'].apply(lambda x: [remove_stop_words(item, stop_words) for item in x])\n",
        "df['processed_text_count'] = df['processed_sentence'].apply(lambda x: sum(map(len, x)))\n",
        "## display results\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "UCctkZi6p9ae",
        "outputId": "13605868-ca24-4277-d0b2-bee0c0eaf041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             FileName                                        MovieReview  \\\n",
              "0  LCK_DOC3_TAKEN.txt  \"Taken,\" which tells the story of how Liam Nee...   \n",
              "1  LCK_DOC9_TAKEN.txt  The conundrum posed by \"Taken\" is as old as ci...   \n",
              "\n",
              "                              MovieReview_normalized  \\\n",
              "0  taken which tells the story of how liam neeson...   \n",
              "1  the conundrum posed by taken is as old as cine...   \n",
              "\n",
              "                                    Review_Sentences  preprocessed_text_count  \\\n",
              "0  [taken which tells the story of how liam neeso...                     3277   \n",
              "1  [the conundrum posed by taken is as old as cin...                     3840   \n",
              "\n",
              "                                  processed_sentence  processed_text_count  \n",
              "0  [taken tells story liam neeson blows gasket fl...                  2268  \n",
              "1  [conundrum posed taken old cinema, stars degra...                  2520  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57902a5c-02ba-44a7-91f8-aa9404a4f9e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>MovieReview</th>\n",
              "      <th>MovieReview_normalized</th>\n",
              "      <th>Review_Sentences</th>\n",
              "      <th>preprocessed_text_count</th>\n",
              "      <th>processed_sentence</th>\n",
              "      <th>processed_text_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LCK_DOC3_TAKEN.txt</td>\n",
              "      <td>\"Taken,\" which tells the story of how Liam Nee...</td>\n",
              "      <td>taken which tells the story of how liam neeson...</td>\n",
              "      <td>[taken which tells the story of how liam neeso...</td>\n",
              "      <td>3277</td>\n",
              "      <td>[taken tells story liam neeson blows gasket fl...</td>\n",
              "      <td>2268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LCK_DOC9_TAKEN.txt</td>\n",
              "      <td>The conundrum posed by \"Taken\" is as old as ci...</td>\n",
              "      <td>the conundrum posed by taken is as old as cine...</td>\n",
              "      <td>[the conundrum posed by taken is as old as cin...</td>\n",
              "      <td>3840</td>\n",
              "      <td>[conundrum posed taken old cinema, stars degra...</td>\n",
              "      <td>2520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57902a5c-02ba-44a7-91f8-aa9404a4f9e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57902a5c-02ba-44a7-91f8-aa9404a4f9e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57902a5c-02ba-44a7-91f8-aa9404a4f9e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-05fef777-a56e-4094-a6c1-6abd5c04f07f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05fef777-a56e-4094-a6c1-6abd5c04f07f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-05fef777-a56e-4094-a6c1-6abd5c04f07f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"FileName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"LCK_DOC4_TAKEN.txt\",\n          \"LCK_DOC9_TAKEN.txt\",\n          \"LCK_DOC5_TAKEN.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MovieReview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"NEXT out of the January dreg-u-lator: A Liam Neeson thriller so lacking in ambition they should have called it \\\"Paycheck.\\\" \\\"Taken,\\\" one of those Frenchy efforts to do an American-style chase-'em-down and shoot-'em-up, comes from formerly respectable producer Luc Besson and director Pierre Morel, whose homegrown, low-budget action thriller \\\"District B13\\\" was a lively little collection of stunts. In trying to broaden their scale to interest a big American audience, Besson and Morel are as convincing as Marcel Marceau doing John Wayne. Neeson plays a retired ex-spook trying to mend fences with the teen daughter, Kim (Maggie Grace), he had with his ex-wife (Famke Janssen), who is still bitter about being neglected during his career as an international undercover agent. We learn that Neeson's Bryan left his teammates in the middle of a mission in Beirut so he could fly 9,000 miles to attend one of his daughter's birthday parties. So which is it: Was he distant or dedicated? And why do his ex-mates think he's such a great guy if he disappears every time he wants to go wrap a present? Bryan is a growly killin' machine trying to find his daughter after she is kidnapped on a trip to Paris. To find his way, he uses a road map of cliches: moldy dialogue (\\\"I will find you. And I will kill you\\\"), improbable escapes from teams of incompetent henchmen (just shoot him in the head, guys  don't handcuff him to a loose overhead pipe) and one of those only-in-the-movies sofas that is bulletproof and fluffy at the same time. When the machine guns roar, just get behind one of these babies and watch the air fill with soft, pretty flurries of stuffing. Available at Crate & Gunbarrel. The movie has two tasks: One is to track Neeson's every step as he pieces together the mystery of where his daughter is. The other is to stage cool chases and gunfights. Both the action and the mystery scenes, though, are made up of such choppy, sloppy, laugh-till-you-drop-y elements that I couldn't figure out whether the movie was rushing through the fights to get back to the mystery or vice versa. An example of how the mystery plays out: Bryan plays a tape of a snippet of conversation between his daughter's attackers to one of his fellow spies. The spy tells him that the men are speaking Albanian, identifies what town they're from, guesses what their game is (trafficking in women to turn into prostitutes) and even explains who their crime boss is. I wish I had a Basil Exposition of my own to decode Neeson's accent. The Irish actor chews over his words as though speaking through a mouthful of mashed potatoes. After half an hour, it dawned on me that he might be trying to sound American, although I couldn't be sure. \\\"You need my permission to leave the coontry?\\\" he asks. The fights and chases are so scrambled that it's hard to figure out basics such as where objects are in relation to one another. Which of the many white SUVs at the construction site is Bryan driving? Where are the other SUVs? Never mind  what I really want to know is, where do the bad guys get these bullets that, when fired at the driver-side window, shatter the glass but stop before reaching the driver's head?\",\n          \"The conundrum posed by \\\"Taken\\\" is as old as cinema itself. Do stars degrade themselves when they take a role in trash, or does their very presence redeem the folly, turning up something that glitters amid the dross? A trenchcoated Robert Mitchum, for instance, sauntered through the villainous Europe of \\\"Foreign Intrigue\\\" (1956), but his saunter is pretty much all that remains; the rest of the movie was forgettable to start with. Now we have another looming hulk, Liam Neeson, laying similar waste to a posse of un-American scoundrels. Like Mitchum, Neeson has shoulders so wide that you have to inspect the back of his jacket to make sure that he didn't leave the coat hanger in. Like Mitchum, too, he appears to move slowly, at his noble leisure, yet to act with daunting swiftness when the occasion demands. He is more alert than Mitchum, whose brand of cool verged on the narcoleptic, but both men lord it over their surroundingsnot with a wink but with a bang. Why spoof the world when you can wreck it with a straight face? In \\\"Taken,\\\" Neeson plays a former C.I.A. hand named Bryan Mills, who is divorced from his wife (Famke Janssen) and living in Los Angeles to be near his daughter Kim (Maggie Grace). If there's one thing we've learned from \\\"California Dreamin',\\\" it's that seventeen-year-old daughters get into scrapes. And if there's one thing we've learned from \\\"24\\\" it's that anybody named Kim, with a father schooled in dirty work by the U.S. government, will have a large echo chamber where her brain is meant to be. Kim and a friend leave for a vacation in Europe, where, ignoring the advice of her father, they are abducted with such consummate speed that it might have been simpler if he had FedExed them directly to the kidnappers. Pausing only to borrow a private jet from his ex's slimy husband, Mills flies to Paris, where he proceeds to work his way, without mercy, through a personal alphabet of undesirable aliens. This being a brisk affair, of little more than ninety minutes, he gets only as far as Albanians and Arabs, but, if I were an innocent Bermudan, let alone a Belgian, I would be starting to get nervous about a sequel. The producer and co-writer is Luc Besson, and the director is Pierre Morel, who made the superior \\\"District B13.\\\" That had Paris under its fingernails, whereas \\\"Taken\\\" darts from one location to the next without probing the city that lies between the hot spots, although Neeson would argue that, once you learn to drive like a Parisian, the opportunities for sightseeing tend to flash past. His performance is the most perturbing thing in the film, even more so than its electrical-torture sequence or its revelations about sex-trafficking; Mills, like some older, vaster brother of Daniel Craig's James Bond, seems driven toor, increasingly, driven byacts of vengeance that are only obliquely related to the wrong that is being avenged. The chop and swipe of his forearms, with or without a knife, become as mechanical as the hammer blows of a blacksmith, and the point at which he casually shoots a friend's wife (who has invited him to stay for supper), in order to extract information from the friend, is either proof of Mills's own madness or, at best, a thoughtful critique of the decline in domestic French cuisine. True, the friend has turned out to be false, but that in itself is a startling development, with Morel and Besson presumably happy to present their native land as not merely spiced with imported peril but intrinsically treacherous. Someone, no doubt, is already composing a thesis on \\\"Symbolic paranoia and American foreign policy in mid-period Neeson,\\\" and you do wonder how this commanding actorwho carries so much more conviction than the plotfelt about delivering the line \\\"I'll tear down the Eiffel Tower if I have to.\\\" The movie opened in France almost a year ago; was it wise to delay its release here until the dawn of the new Presidency, when it so clearly belongs to the last one?\",\n          \"Thank heavens Liam Neeson is getting old. At 56, he's \\\"taken\\\" a bit of a career turn playing a lethal black ops action hero, a type of role he's apparently avoided throughout his illustrious career. But perhaps the meatier roles are getting thin these days, so who better to star in \\\"Taken\\\" than an Irish actor with the breadth and depth of the former Oskar Shindler, Jean Valjean, and Jedi Master Qui-Gon Jinn for crying out loud? (Not to mention the upcoming Abraham Lincoln in a pic by Steven Spielberg). Neeson is a major reason \\\"Taken,\\\" a riveting, revenge thriller gets praiseworthy marks. The body count is as high as the amount of coincidences that seem to work out in retired CIA agent Bryan Mills' (Neeson) favor. If you are willing to give the movie a little latitude, \\\"Taken\\\" is smart and fast enough to please most everyone. Mills tries to make up for lost time with his now estranged 17-year-old daughter (Fresh faced Maggie Grace) and struggles for her attention with his unforgiving ex-wife (Famke Janssen) and her new mega-rich hubby (Xander Berkeley). He kills time eating Chinese take-out with his fellow retired agents, and helping with occasional security jobs like body guarding celebrity pop singers. His worst fears about his daughters' trip to Paris with a girl friend are confirmed when they get kidnapped and are forced into a sordid slavery/prostitution ring headed up by a gang of Albanian thugs. But Mills has skills, a \\\"particular set of skills...\\\" that allow him to make good on his promise to his daughters' captors: \\\"I will look for you, I will find you. And I will kill you.\\\" It's not hard to believe everything Neeson says on screen and so we have a Bourne-like manhunt story grounded in the gravitas of a tall, foreboding Oscar nominee who wears a friendly fury on his face like few actors. There's a point in these types of action films where plausibility flys out the glass- plated windows so pervasive in this genre, but if the film at least makes attempts to show a reasonable amount of reality then some type of standard has been met. Could a trained killing machine recognize the source of a two-word statement by a foreign stranger recorded on a cell phone? Yes, if we see him studying it meticulously. Would he shoot, without killing mind you, an innocent to prove a point? Who knows? But it makes for a great action picture moment. Speaking of killing, if you're going to be a killjoy and dwell on this film's implausibilities, stay home and let the rest of us enjoy the rush.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MovieReview_normalized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"next out of the january dregulator a liam neeson thriller so lacking in ambition they should have called it paycheck taken one of those frenchy efforts to do an americanstyle chaseemdown and shootemup comes from formerly respectable producer luc besson and director pierre morel whose homegrown lowbudget action thriller district b13 was a lively little collection of stunts in trying to broaden their scale to interest a big american audience besson and morel are as convincing as marcel marceau doing john wayne neeson plays a retired exspook trying to mend fences with the teen daughter kim maggie grace he had with his exwife famke janssen who is still bitter about being neglected during his career as an international undercover agent we learn that neesons bryan left his teammates in the middle of a mission in beirut so he could fly 9000 miles to attend one of his daughters birthday parties so which is it was he distant or dedicated and why do his exmates think hes such a great guy if he disappears every time he wants to go wrap a present bryan is a growly killin machine trying to find his daughter after she is kidnapped on a trip to paris to find his way he uses a road map of cliches moldy dialogue i will find you and i will kill you improbable escapes from teams of incompetent henchmen just shoot him in the head guys  dont handcuff him to a loose overhead pipe and one of those onlyinthemovies sofas that is bulletproof and fluffy at the same time when the machine guns roar just get behind one of these babies and watch the air fill with soft pretty flurries of stuffing available at crate  gunbarrel the movie has two tasks one is to track neesons every step as he pieces together the mystery of where his daughter is the other is to stage cool chases and gunfights both the action and the mystery scenes though are made up of such choppy sloppy laughtillyoudropy elements that i couldnt figure out whether the movie was rushing through the fights to get back to the mystery or vice versa an example of how the mystery plays out bryan plays a tape of a snippet of conversation between his daughters attackers to one of his fellow spies the spy tells him that the men are speaking albanian identifies what town theyre from guesses what their game is trafficking in women to turn into prostitutes and even explains who their crime boss is i wish i had a basil exposition of my own to decode neesons accent the irish actor chews over his words as though speaking through a mouthful of mashed potatoes after half an hour it dawned on me that he might be trying to sound american although i couldnt be sure you need my permission to leave the coontry he asks the fights and chases are so scrambled that its hard to figure out basics such as where objects are in relation to one another which of the many white suvs at the construction site is bryan driving where are the other suvs never mind  what i really want to know is where do the bad guys get these bullets that when fired at the driverside window shatter the glass but stop before reaching the drivers head\",\n          \"the conundrum posed by taken is as old as cinema itself do stars degrade themselves when they take a role in trash or does their very presence redeem the folly turning up something that glitters amid the dross a trenchcoated robert mitchum for instance sauntered through the villainous europe of foreign intrigue 1956 but his saunter is pretty much all that remains the rest of the movie was forgettable to start with now we have another looming hulk liam neeson laying similar waste to a posse of unamerican scoundrels like mitchum neeson has shoulders so wide that you have to inspect the back of his jacket to make sure that he didnt leave the coat hanger in like mitchum too he appears to move slowly at his noble leisure yet to act with daunting swiftness when the occasion demands he is more alert than mitchum whose brand of cool verged on the narcoleptic but both men lord it over their surroundingsnot with a wink but with a bang why spoof the world when you can wreck it with a straight face in taken neeson plays a former cia hand named bryan mills who is divorced from his wife famke janssen and living in los angeles to be near his daughter kim maggie grace if theres one thing weve learned from california dreamin its that seventeenyearold daughters get into scrapes and if theres one thing weve learned from 24 its that anybody named kim with a father schooled in dirty work by the us government will have a large echo chamber where her brain is meant to be kim and a friend leave for a vacation in europe where ignoring the advice of her father they are abducted with such consummate speed that it might have been simpler if he had fedexed them directly to the kidnappers pausing only to borrow a private jet from his exs slimy husband mills flies to paris where he proceeds to work his way without mercy through a personal alphabet of undesirable aliens this being a brisk affair of little more than ninety minutes he gets only as far as albanians and arabs but if i were an innocent bermudan let alone a belgian i would be starting to get nervous about a sequel the producer and cowriter is luc besson and the director is pierre morel who made the superior district b13 that had paris under its fingernails whereas taken darts from one location to the next without probing the city that lies between the hot spots although neeson would argue that once you learn to drive like a parisian the opportunities for sightseeing tend to flash past his performance is the most perturbing thing in the film even more so than its electricaltorture sequence or its revelations about sextrafficking mills like some older vaster brother of daniel craigs james bond seems driven toor increasingly driven byacts of vengeance that are only obliquely related to the wrong that is being avenged the chop and swipe of his forearms with or without a knife become as mechanical as the hammer blows of a blacksmith and the point at which he casually shoots a friends wife who has invited him to stay for supper in order to extract information from the friend is either proof of millss own madness or at best a thoughtful critique of the decline in domestic french cuisine true the friend has turned out to be false but that in itself is a startling development with morel and besson presumably happy to present their native land as not merely spiced with imported peril but intrinsically treacherous someone no doubt is already composing a thesis on symbolic paranoia and american foreign policy in midperiod neeson and you do wonder how this commanding actorwho carries so much more conviction than the plotfelt about delivering the line ill tear down the eiffel tower if i have to the movie opened in france almost a year ago was it wise to delay its release here until the dawn of the new presidency when it so clearly belongs to the last one\",\n          \"thank heavens liam neeson is getting old at 56 hes taken a bit of a career turn playing a lethal black ops action hero a type of role hes apparently avoided throughout his illustrious career but perhaps the meatier roles are getting thin these days so who better to star in taken than an irish actor with the breadth and depth of the former oskar shindler jean valjean and jedi master quigon jinn for crying out loud not to mention the upcoming abraham lincoln in a pic by steven spielberg neeson is a major reason taken a riveting revenge thriller gets praiseworthy marks the body count is as high as the amount of coincidences that seem to work out in retired cia agent bryan mills neeson favor if you are willing to give the movie a little latitude taken is smart and fast enough to please most everyone mills tries to make up for lost time with his now estranged 17yearold daughter fresh faced maggie grace and struggles for her attention with his unforgiving exwife famke janssen and her new megarich hubby xander berkeley he kills time eating chinese takeout with his fellow retired agents and helping with occasional security jobs like body guarding celebrity pop singers his worst fears about his daughters trip to paris with a girl friend are confirmed when they get kidnapped and are forced into a sordid slaveryprostitution ring headed up by a gang of albanian thugs but mills has skills a particular set of skills that allow him to make good on his promise to his daughters captors i will look for you i will find you and i will kill you its not hard to believe everything neeson says on screen and so we have a bournelike manhunt story grounded in the gravitas of a tall foreboding oscar nominee who wears a friendly fury on his face like few actors theres a point in these types of action films where plausibility flys out the glass plated windows so pervasive in this genre but if the film at least makes attempts to show a reasonable amount of reality then some type of standard has been met could a trained killing machine recognize the source of a twoword statement by a foreign stranger recorded on a cell phone yes if we see him studying it meticulously would he shoot without killing mind you an innocent to prove a point who knows but it makes for a great action picture moment speaking of killing if youre going to be a killjoy and dwell on this films implausibilities stay home and let the rest of us enjoy the rush\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review_Sentences\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_text_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1229,\n        \"min\": 2439,\n        \"max\": 6738,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          3081,\n          3840,\n          2439\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_sentence\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_text_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 791,\n        \"min\": 1746,\n        \"max\": 4514,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2016,\n          2520,\n          1746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## from discussion 2 term extraction code sample\n",
        "## reference: Jennifer Sleeman\n",
        "extracted_terms2 = []\n",
        "for i in range(10):\n",
        "  sentences2 = df['processed_sentence'][i]\n",
        "  all_terms2=[]\n",
        "  for sentence in sentences2:\n",
        "    all_terms2 = all_terms2 + run_rake(sentence)\n",
        "  #get the frequency distribution across the terms\n",
        "  fd2=get_freq_dist(all_terms2).most_common(15)\n",
        "\n",
        "  for t in fd2:\n",
        "    if len(t[0][1])>2 and t[0][1] not in extracted_terms2:\n",
        "      extracted_terms2.append(t[0][1])"
      ],
      "metadata": {
        "id": "YOwRvAUit4l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'For nltk term extraction from the 10 movie reviews there were {len(extracted_terms2)} terms occured most frequently in the pre-processed text review sentences')\n",
        "print(f'The result of the text pre-processing reduced the total number of terms extracted using NLTK by {len(extracted_terms) - len(extracted_terms2)} terms.')\n",
        "print(f'For nltk term extraction with pre-processing {len(extracted_terms2)} (stop word removal, numeric digits removed)')\n",
        "print(f'For nltk term extraction without pre-processing {len(extracted_terms)} (lower case and special characters removed)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxeLjgXVvOdg",
        "outputId": "ddb90085-b145-421d-f2ee-b0f51a3afc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For nltk term extraction from the 10 movie reviews there were 32 terms occured most frequently in the pre-processed text review sentences\n",
            "The result of the text pre-processing reduced the total number of terms extracted using NLTK by 99 terms.\n",
            "For nltk term extraction with pre-processing 32 (stop word removal, numeric digits removed)\n",
            "For nltk term extraction without pre-processing 131 (lower case and special characters removed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_terms_nltk2 = get_matched_term_list(extracted_terms, extracted_terms2)\n",
        "matched_terms_manual = get_matched_term_list(cleaned_terms, extracted_terms2)\n",
        "print(f'For nltk term extraction the number of matched terms between the two NLTK processes returns {len(matched_terms_nltk2)}')\n",
        "print(f'For nltk term extraction the number of matched terms between the manual and the increased text preprocessing is {len(matched_terms_manual)}')\n",
        "print(f'A sample of the matched terms between the methods are: {matched_terms_nltk2[:6]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlB3KuQCu7TF",
        "outputId": "722764c8-e07e-4db3-e4bf-3b7b9736704e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For nltk term extraction the number of matched terms between the two NLTK processes returns 19\n",
            "For nltk term extraction the number of matched terms between the manual and the increased text preprocessing is 3\n",
            "A sample of the matched terms between the methods are: ['taken', 'kills 75 albanians', 'old', 'end', 'look', 'skilled']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_term_list = merged_term_list + extracted_terms2\n",
        "## remove duplicates\n",
        "merged_term_list = list(set(merged_term_list))\n",
        "print(f'The total number of terms between the various methods: {len(merged_term_list)}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-mvUQHOzUao",
        "outputId": "843ab0aa-4a37-41a1-d065-817b1b38fae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of terms between the various methods: 629.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Step 5: Normalize aliases / synonyms </h2>\n",
        "<ul>\n",
        "<li>Identify cases where different terms reference the same thing (e.g. 'paris', 'arrondisment', 'charles de gaulle international', 'eiffel tower').</li>\n",
        "</ul>\n",
        "Code reference for synonyms and antonyms NLTK use:<br>\n",
        "Subramanian, Dhilip. 2019. \"Synonyms and Antonyms in Python\n",
        "Text Mining — Extracting Synonyms and Antonyms.\" Medium.com\n",
        "https://medium.com/data-science/synonyms-and-antonyms-in-python-a865a5e14ce8"
      ],
      "metadata": {
        "id": "c507t82cwmg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking synonym for the word \"travel\"\n",
        "from nltk.corpus import wordnet\n",
        "def get_syn(term):\n",
        "  synonyms = []\n",
        "  for syn in wordnet.synsets(term):\n",
        "    for lm in syn.lemmas():\n",
        "      if lm.name() not in synonyms:\n",
        "             synonyms.append(lm.name())#adding into synonyms\n",
        "  return synonyms\n",
        "\n",
        "alias = {}\n",
        "for t in merged_term_list:\n",
        "  ## check alias values\n",
        "  for a in list(alias.keys()):\n",
        "    if t in alias[a]:\n",
        "      alias[a].append(t)\n",
        "      break\n",
        "  if t not in alias:\n",
        "    alias[t] = get_syn(t)"
      ],
      "metadata": {
        "id": "M4SxnN7MwloY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_syn_terms = os.path.join(destination_folder, \"LCK_Alias_Terms.json\")\n",
        "with open(movie_syn_terms, 'r') as f:\n",
        "  syn = json.load(f)\n"
      ],
      "metadata": {
        "id": "z392aG1C2r7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the summary of aliased terms within each document"
      ],
      "metadata": {
        "id": "rn4z_I1AZJUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## generate dataframe frequncy count in reviews\n",
        "df_alias_summary = check_terms_in_df(df, merged_term_list, alias_terms = syn[0])\n",
        "#df_alias_summary.sort_values(by='alias_terms', ascending = False, inplace=True)"
      ],
      "metadata": {
        "id": "fKzyyiiKJBIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## display the top 15 results\n",
        "df_alias_summary.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "_L-C1iOtJLt5",
        "outputId": "d4f8b378-f7e5-40ea-9b95-05f3efd9027e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Term  DOC3  DOC9  DOC10  DOC7  DOC6  DOC5  DOC8  DOC1  DOC4  DOC2  \\\n",
              "0         la    11    12     15    14    14     9     3     8    10    11   \n",
              "1         us    10     6     25    15     4     7     7    12     4     9   \n",
              "2         no     8    10     21     8     7     7    11     8     2    11   \n",
              "3        one     2     6      9    15     8     2     3     8     7     8   \n",
              "4      taken     2     3      6     3     1     4    15    11     1     3   \n",
              "5        all     4     3      8     4     3     2     6     6     2     6   \n",
              "6        end     5     5     12     3     2     2     2     4     2     6   \n",
              "7        ive     3     5      6     6     3     3     5     3     3     5   \n",
              "8      bryan     7     1     10     1     6     1     3     0     4     7   \n",
              "9        man     1     3     15     2     3     1     3     5     1     4   \n",
              "10    action     1     0      5     4     4     3    12     4     2     2   \n",
              "11    neeson     5     5      3     3     3     4     5     2     5     2   \n",
              "12     movie     1     2     15     5     2     1     0     6     3     1   \n",
              "13       men     4     3      6     6     2     3     2     5     5     0   \n",
              "14  daughter     7     2      6     3     2     3     1     2     5     3   \n",
              "15       hes     0     1      6     4     3     4     0     3     4     7   \n",
              "16     thing     1     4      7     2     1     1     7     5     0     3   \n",
              "17      kill     1     0      5     3     2     8     0     1     2     3   \n",
              "18     paris     1     3      5     2     4     1     1     2     1     5   \n",
              "19       cia     3     1      3     6     2     1     0     4     0     5   \n",
              "20      film     1     1      9     1     0     3     6     3     0     1   \n",
              "21       kim     0     3      5     7     5     0     0     0     1     3   \n",
              "22       old     4     3      4     2     3     2     1     1     1     2   \n",
              "23       way     3     1      4     2     3     0     2     3     2     3   \n",
              "24     mills     1     4      1     8     1     3     2     0     0     1   \n",
              "25    friend     4     4      4     1     1     2     0     0     0     1   \n",
              "26     other     0     2      5     3     2     0     1     1     3     0   \n",
              "27       car     1     1      4     2     2     3     0     0     1     3   \n",
              "28      time     1     0      3     4     2     2     0     1     2     1   \n",
              "29       use     2     0      3     4     0     0     1     4     1     0   \n",
              "\n",
              "    TotalTerms  alias_terms  \n",
              "0          107  los angeles  \n",
              "1           99      america  \n",
              "2           93           no  \n",
              "3           68          one  \n",
              "4           49        taken  \n",
              "5           44          all  \n",
              "6           43          end  \n",
              "7           42          ive  \n",
              "8           40  bryan mills  \n",
              "9           38          man  \n",
              "10          37       action  \n",
              "11          37  liam neeson  \n",
              "12          36        movie  \n",
              "13          36          man  \n",
              "14          34     daughter  \n",
              "15          32          hes  \n",
              "16          31        thing  \n",
              "17          25         kill  \n",
              "18          25        paris  \n",
              "19          25          cia  \n",
              "20          25        movie  \n",
              "21          24          kim  \n",
              "22          23          old  \n",
              "23          23          way  \n",
              "24          21  bryan mills  \n",
              "25          17       friend  \n",
              "26          17        other  \n",
              "27          17   automobile  \n",
              "28          16         time  \n",
              "29          15          use  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e05182b-6c9b-4795-92a3-b8bfa586d216\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>DOC3</th>\n",
              "      <th>DOC9</th>\n",
              "      <th>DOC10</th>\n",
              "      <th>DOC7</th>\n",
              "      <th>DOC6</th>\n",
              "      <th>DOC5</th>\n",
              "      <th>DOC8</th>\n",
              "      <th>DOC1</th>\n",
              "      <th>DOC4</th>\n",
              "      <th>DOC2</th>\n",
              "      <th>TotalTerms</th>\n",
              "      <th>alias_terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>la</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>107</td>\n",
              "      <td>los angeles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>us</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>99</td>\n",
              "      <td>america</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>93</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>one</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>68</td>\n",
              "      <td>one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>taken</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>taken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>all</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>44</td>\n",
              "      <td>all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>end</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ive</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>42</td>\n",
              "      <td>ive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>bryan</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>40</td>\n",
              "      <td>bryan mills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>man</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>action</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>neeson</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>liam neeson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>movie</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>men</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>daughter</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>34</td>\n",
              "      <td>daughter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hes</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>32</td>\n",
              "      <td>hes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>thing</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>kill</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>kill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>paris</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "      <td>paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>cia</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "      <td>cia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>film</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>kim</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>kim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>old</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>old</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>way</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>way</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>mills</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>bryan mills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>friend</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>other</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>car</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>time</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>use</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e05182b-6c9b-4795-92a3-b8bfa586d216')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e05182b-6c9b-4795-92a3-b8bfa586d216 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e05182b-6c9b-4795-92a3-b8bfa586d216');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9eeb1da4-59b1-466e-99d7-f9a0fd529ff4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9eeb1da4-59b1-466e-99d7-f9a0fd529ff4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9eeb1da4-59b1-466e-99d7-f9a0fd529ff4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_alias_summary",
              "summary": "{\n  \"name\": \"df_alias_summary\",\n  \"rows\": 521,\n  \"fields\": [\n    {\n      \"column\": \"Term\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 521,\n        \"samples\": [\n          \"french connection\",\n          \"district b13\",\n          \"end\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1,\n          10,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          2,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 25,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          3,\n          4,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          6,\n          14,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7,\n          1,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          2,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2,\n          12,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4,\n          3,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOC2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          5,\n          11,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 107,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          1,\n          32,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alias_terms\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 422,\n        \"samples\": [\n          \"dont know\",\n          \"heroin\",\n          \"prisoner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_alias_terms = len(df_alias_summary['alias_terms'].unique())\n",
        "print(f'The total number of alias terms {num_alias_terms}, a {len(merged_term_list)-num_alias_terms} reduction from the original term list.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0O6SOqXE4dF",
        "outputId": "7db8a5b4-5600-446e-e0af-5bbd5bba57fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of alias terms 422, a 207 reduction from the original term list.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the values from the dictionary\n",
        "alias_values = syn[0].values()\n",
        "\n",
        "# Use Counter to count the occurrences of each value\n",
        "value_counts = {}\n",
        "\n",
        "for k,v in syn[0].items():\n",
        "  if v not in value_counts.keys():\n",
        "    value_counts[v]={}\n",
        "    value_counts[v]['original_terms'] = [k]\n",
        "    value_counts[v]['count'] = 1\n",
        "  else:\n",
        "    value_counts[v]['original_terms'].append(k)\n",
        "    value_counts[v]['count'] += 1\n",
        "\n",
        "top_alias_terms = {}\n",
        "for k,v in value_counts.items():\n",
        "  if v['count']>=5:\n",
        "    top_alias_terms[k] = v\n",
        "\n",
        "top_alias_terms\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB9V73n9ULm3",
        "outputId": "ccc450af-6afd-4280-d3ce-2600576d78e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'action movie': {'original_terms': ['action choreography',\n",
              "   'action film',\n",
              "   'action movie',\n",
              "   'action thriller',\n",
              "   'action thrillers',\n",
              "   'actionthriller'],\n",
              "  'count': 6},\n",
              " 'criminals': {'original_terms': ['albanian nasties',\n",
              "   'albanian ring',\n",
              "   'albanian thugs',\n",
              "   'criminals',\n",
              "   'posse'],\n",
              "  'count': 5},\n",
              " 'sex traffickers': {'original_terms': ['albanian sex traffickers',\n",
              "   'albanian white slavers',\n",
              "   'nasty whiteslave traders',\n",
              "   'sex traffickers',\n",
              "   'sex trafficking',\n",
              "   'sexual slavery',\n",
              "   'trafficking in women',\n",
              "   'white slave ring',\n",
              "   'white slavers',\n",
              "   'whiteslave traders'],\n",
              "  'count': 10},\n",
              " 'jason bourne': {'original_terms': ['bourne',\n",
              "   'bourne thriller',\n",
              "   'bournelike',\n",
              "   'bournelike manhunt',\n",
              "   'jason bourne',\n",
              "   'jason bournelike skills',\n",
              "   'jason ourneesque'],\n",
              "  'count': 7},\n",
              " 'bryan mills': {'original_terms': ['bryan',\n",
              "   'bryan hours find',\n",
              "   'bryan may',\n",
              "   'bryan mills',\n",
              "   'mills',\n",
              "   'taken shows mills'],\n",
              "  'count': 6},\n",
              " 'spy': {'original_terms': ['espionage',\n",
              "   'retired spy',\n",
              "   'spook',\n",
              "   'spy',\n",
              "   'spycraft'],\n",
              "  'count': 5},\n",
              " 'movie': {'original_terms': ['film',\n",
              "   'movie',\n",
              "   'movies',\n",
              "   'pic',\n",
              "   'picture',\n",
              "   'story'],\n",
              "  'count': 6}}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_google_check['extracted_terms_count'] = df_google_check[['Ground_Truth','GPT','Dandelion','NLTK','Google']].sum(axis=1)\n",
        "df_google_check.sort_values(by='extracted_terms_count', ascending = False, inplace=True)\n",
        "top_terms_df = df_google_check.loc[df_google_check['extracted_terms_count']>=2].copy()\n",
        "top_terms_df['alias'] = top_terms_df['Term'].map(syn[0])\n",
        "top_terms = list(top_terms_df['alias'].unique())\n",
        "\n",
        "\n",
        "print(f'The number of top terms between term extraction methods is: {len(top_terms)}.')\n",
        "print(f'A sample of the top terms between all the the methods are: {top_terms[:10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH6Jpwomkipl",
        "outputId": "a4993688-49d2-492c-dd77-f6e96dd14abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of top terms between term extraction methods is: 105.\n",
            "A sample of the top terms between all the the methods are: ['paris', 'liam neeson', 'pierre morel', 'famke janssen', 'maggie grace', 'cia', 'steven spielberg', 'osama bin laden', 'luc besson', 'bryan mills']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extraction_engines = ['Ground_Truth','GPT','Dandelion','NLTK','Google']\n",
        "results = []\n",
        "for e in extraction_engines:\n",
        "  results.append([ int(top_terms_df[e].sum()), e])"
      ],
      "metadata": {
        "id": "kwC75USbwn-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(results, reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq2gFubxzxqg",
        "outputId": "c6814055-8c81-4688-b17d-6718d9e2804a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[75, 'Dandelion'],\n",
              " [64, 'Ground_Truth'],\n",
              " [55, 'Google'],\n",
              " [45, 'GPT'],\n",
              " [38, 'NLTK']]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_terms = os.path.join(destination_folder, \"LCK_Extracted_Terms.json\")\n",
        "with open(movie_terms, \"w\", encoding=\"utf-8\") as file:\n",
        "        json.dump(top_terms, file, indent=4)\n",
        "\n",
        "print(\"List successfully saved file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpfC-7COVbem",
        "outputId": "50031ae0-08ba-4348-de81-88b5dd70d8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List successfully saved file\n"
          ]
        }
      ]
    }
  ]
}